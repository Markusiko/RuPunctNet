# Эксперименты с моделями

В данной папке содержатся все ноутбуки ML-экспериментами. Их краткое описание:
* `baseline_modelling.ipynb` $-$ ноутбук с подсчетом метрик для обученной логистической регрессии на эмбеддингах Navec и XLM-Roberta с HuggingFace;
* `simple_rules.ipynb` $-$ ноутбук с подсчетом метрик для алгоритмов на простых правилах расстановки знаков пунктуации;
* `gigachat.ipynb` $-$ ноутбук с подсчетом метрик для LLM GigaChat.

В качестве основных метрик используются Recall, Precision, F1-Score в разрезе каждого класса. Для логистической регрессии также считаются метрики AUC-PR, ROC-AUC. С метриками можно ознакомиться в ноутбуках соответствующих подходов. 

Отметим, что метрики лишь приблизительно сопоставимы: GigaChat, например, иногда отказывался генерировать или генерировал больше слов/лишние слова, поэтому были оставлены лишь пары, где число слов совпадало. Все сгенерированные GigaChat`ом тексты можно посмотреть в файле `gigachat_preds_test.txt`. 

Исходя из экспериментов лучшими моделями оказались XLM-Roberta и GigaChat (примерно одинаковы). Ожидаемо, логистическая регрессия на простых эмбеддингах и простые правила им сильно проиграли.
