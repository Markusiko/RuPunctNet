{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "5a3cc225",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# from gensim.models import Word2Vec\n",
    "import tqdm\n",
    "import ast\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from navec import Navec\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, top_k_accuracy_score,\\\n",
    "                            f1_score, precision_score, recall_score, average_precision_score\n",
    "from joblib import dump\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55655f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('final_markup/train.csv').sample(n=20000, random_state=999)\n",
    "df_val = pd.read_csv('final_markup/val.csv').sample(n=5000, random_state=999)\n",
    "df_test = pd.read_csv('final_markup/test.csv').sample(n=5000, random_state=999)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4069a94",
   "metadata": {},
   "source": [
    "## Логистическая регрессия на эмбеддингах Navec\n",
    "\n",
    "Эмбеддинги Navec не учитывают никакой контекст, поэтому от решения не ожидается ничего впечатляющего и мы будем его использовать для проверки работы сервиса (tg-бота) и подсчета метрик"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6eebcbba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget https://storage.yandexcloud.net/natasha-navec/packs/navec_hudlit_v1_12B_500K_300d_100q.tar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "756eebaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'navec_hudlit_v1_12B_500K_300d_100q.tar'\n",
    "navec = Navec.load(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa4cf75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeds(data):\n",
    "    '''\n",
    "    Функция для получения эмбеддингов слов предложений из data.\n",
    "    Также возвращает таргет для каждого слова\n",
    "    '''\n",
    "    data_lst = []\n",
    "\n",
    "    for i in tqdm.tqdm(data):\n",
    "        list_of_words = ast.literal_eval(i[1])\n",
    "        list_of_targets = ast.literal_eval(i[2])\n",
    "    \n",
    "        for i in range(len(list_of_targets)):\n",
    "            try:\n",
    "                data_lst.append([*navec[list_of_words[i]], list_of_targets[i]])\n",
    "            except:\n",
    "                data_lst.append([*navec['<unk>'], list_of_targets[i]])\n",
    "                \n",
    "    return pd.DataFrame(data_lst, \n",
    "                        columns=[f'embed_{i}' for i in range(300)] + ['target'])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "284bb941",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 20000/20000 [01:06<00:00, 298.83it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 476.84it/s]\n",
      "100%|██████████████████████████████████████| 5000/5000 [00:10<00:00, 457.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 50s, sys: 1min 5s, total: 4min 55s\n",
      "Wall time: 5min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "train_embed = get_embeds(df_train.values)\n",
    "val_embed = get_embeds(df_val.values)\n",
    "test_embed = get_embeds(df_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e514760e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(838808, 215133, 211519)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_embed), len(val_embed), len(test_embed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "261e94d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>val</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>o</th>\n",
       "      <td>711878</td>\n",
       "      <td>182407</td>\n",
       "      <td>179729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>,</th>\n",
       "      <td>64023</td>\n",
       "      <td>16800</td>\n",
       "      <td>15944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>.</th>\n",
       "      <td>58385</td>\n",
       "      <td>14863</td>\n",
       "      <td>14654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>:</th>\n",
       "      <td>2293</td>\n",
       "      <td>531</td>\n",
       "      <td>567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>;</th>\n",
       "      <td>1792</td>\n",
       "      <td>411</td>\n",
       "      <td>512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>?</th>\n",
       "      <td>196</td>\n",
       "      <td>52</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>!</th>\n",
       "      <td>176</td>\n",
       "      <td>47</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>65</td>\n",
       "      <td>22</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train     val    test\n",
       "o    711878  182407  179729\n",
       ",     64023   16800   15944\n",
       ".     58385   14863   14654\n",
       ":      2293     531     567\n",
       ";      1792     411     512\n",
       "?       196      52      54\n",
       "!       176      47      48\n",
       "...      65      22      11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_counts_df = pd.concat([train_embed.target.value_counts(),\n",
    "                              val_embed.target.value_counts(),\n",
    "                              test_embed.target.value_counts()], axis=1)\n",
    "\n",
    "target_counts_df.columns = ['train', 'val', 'test']\n",
    "target_counts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e88d4f",
   "metadata": {},
   "source": [
    "Как видно, очень мало предложений со знаками `! ? ...`. Причиной этого является рандомное сэмплирование из разметки, в которой преобладали текста из Википедии"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3b122084",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder().fit(train_embed['target'])\n",
    "\n",
    "model = LogisticRegression(max_iter=10000).fit(train_embed.drop('target', axis=1),\n",
    "                                 le.transform(train_embed['target']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1fc06e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(test_embed.drop('target', axis=1))\n",
    "y_pred_proba = model.predict_proba(test_embed.drop('target', axis=1))\n",
    "y_true = le.transform(test_embed['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "1b212fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics(y_true, y_pred, y_pred_proba):\n",
    "    print('Доля пробелов:', (y_true == 7).mean())\n",
    "    print('Accuracy:', top_k_accuracy_score(y_true, y_pred_proba, k=1))\n",
    "    print('Top-2 Accuracy:', top_k_accuracy_score(y_true, y_pred_proba, k=2))\n",
    "    print('ROC-AUC (OVR):',roc_auc_score(y_true, y_pred_proba, multi_class='ovr'))\n",
    "    print('AUC-PR:',average_precision_score(y_true, y_pred_proba, average='weighted'))\n",
    "    \n",
    "    metrics = []\n",
    "    metrics.append(list(dict(sorted(Counter(y_true).items())).values()))\n",
    "    metrics.append(f1_score(y_true, y_pred, average=None))\n",
    "    metrics.append(precision_score(y_true, y_pred, average=None, zero_division=0))\n",
    "    metrics.append(recall_score(y_true, y_pred, average=None, zero_division=0))\n",
    "    metrics.append(roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average=None))\n",
    "    metrics.append(average_precision_score(y_true, y_pred_proba, average=None))\n",
    "    metrics_index = ['Count', 'F1-Score', 'Precision', 'Recall', 'ROC-AUC', 'AUC-PR']\n",
    "    df_metrics = pd.DataFrame(metrics, columns=le.classes_, index=metrics_index)\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "8894eba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля пробелов: 0.8497061729679131\n",
      "Accuracy: 0.8544527914749975\n",
      "Top-2 Accuracy: 0.9338877358535167\n",
      "ROC-AUC (OVR): 0.7555137348366741\n",
      "AUC-PR: 0.8163815439633352\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>:</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>48.000000</td>\n",
       "      <td>15944.000000</td>\n",
       "      <td>14654.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>567.000000</td>\n",
       "      <td>512.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>179729.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.144237</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.921261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>0.832973</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.854643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.078955</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ROC-AUC</th>\n",
       "      <td>0.810487</td>\n",
       "      <td>0.679878</td>\n",
       "      <td>0.714230</td>\n",
       "      <td>0.890871</td>\n",
       "      <td>0.709458</td>\n",
       "      <td>0.710344</td>\n",
       "      <td>0.821617</td>\n",
       "      <td>0.707224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AUC-PR</th>\n",
       "      <td>0.005221</td>\n",
       "      <td>0.125714</td>\n",
       "      <td>0.229541</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.009757</td>\n",
       "      <td>0.006743</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>0.930859</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   !             ,             .        ...           :  \\\n",
       "Count      48.000000  15944.000000  14654.000000  11.000000  567.000000   \n",
       "F1-Score    0.000000      0.000125      0.144237   0.000000    0.000000   \n",
       "Precision   0.000000      0.076923      0.832973   0.000000    0.000000   \n",
       "Recall      0.000000      0.000063      0.078955   0.000000    0.000000   \n",
       "ROC-AUC     0.810487      0.679878      0.714230   0.890871    0.709458   \n",
       "AUC-PR      0.005221      0.125714      0.229541   0.000949    0.009757   \n",
       "\n",
       "                    ;          ?              o  \n",
       "Count      512.000000  54.000000  179729.000000  \n",
       "F1-Score     0.000000   0.000000       0.921261  \n",
       "Precision    0.000000   0.000000       0.854643  \n",
       "Recall       0.000000   0.000000       0.999143  \n",
       "ROC-AUC      0.710344   0.821617       0.707224  \n",
       "AUC-PR       0.006743   0.008290       0.930859  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics(y_true, y_pred, y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "29e2cdbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(le, 'le.joblib')\n",
    "dump(model, 'log_reg.joblib');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626d2e02",
   "metadata": {},
   "source": [
    "## Готовая опенсурс-модель\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da53c2",
   "metadata": {},
   "source": [
    "А почему бы не взять готовую модель и не постараться ее улучшить/превзойти в будущем. Для тестирования была взята [XLM Roberta](https://huggingface.co/1-800-BAD-CODE/xlm-roberta_punctuation_fullstop_truecase). Модель весьма хороша и может быть использована в качестве финальной: умеет в 47 языков, также умеет разделять текст на предложения и делать заглавными нужные буквы.\n",
    "\n",
    "<img src=https://cdn-uploads.huggingface.co/production/uploads/62d34c813eebd640a4f97587/WJ8aWIM4A--xzYu8FR4ht.png alt=\"drawing\" width=\"700\"/>\n",
    "\n",
    "Конечно, такую модель потенциально будет нелегко побить. Однако, возможно, это удастся сделать, так как мы будем упираться лишь в один язык, а не в 47. В любом случае посмотрим на метрики, которые показывает модель:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "e2490b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install punctuators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "08a6b32e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет, как дела? Это новый кадиллак.'"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from punctuators.models import PunctCapSegModelONNX\n",
    "\n",
    "m = PunctCapSegModelONNX.from_pretrained(\n",
    "    \"1-800-BAD-CODE/xlm-roberta_punctuation_fullstop_truecase\"\n",
    ")\n",
    "\n",
    "input_texts = [\n",
    "    'привет как дела это новый кадиллак'\n",
    "]\n",
    "\n",
    "results = m.infer(\n",
    "    texts=input_texts, apply_sbd=True,\n",
    ")\n",
    "\n",
    "' '.join(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "9707ca7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Привет, как дела? Это новый кадиллак.']"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "0c60eb8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Привет, как дела? Это новый кадиллак.'"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = m.infer(\n",
    "    texts=input_texts, apply_sbd=False,\n",
    ")\n",
    "\n",
    "results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "2b6a4bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "punctuation_signs = ['!', ',', '.', '...', ':', ';', '?']\n",
    "\n",
    "def roberta_prediction(text):\n",
    "    text = re.sub('– ', '', text)\n",
    "    text = re.sub('— ', '', text)\n",
    "    text = re.sub('\"', '', text)\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    for sign in punctuation_signs:\n",
    "        text = text.replace(sign + ' ', ' ')\n",
    "        \n",
    "    if text[-1] in punctuation_signs:\n",
    "        text = text[:-1]\n",
    "        \n",
    "    preds = m.infer(\n",
    "    texts=[text], apply_sbd=False,\n",
    "    )\n",
    "    prediction = preds[0]\n",
    "    tokens = [token for token in prediction.split(' ') if token != '']\n",
    "    labels = []\n",
    "    \n",
    "    for token in tokens:\n",
    "        if (len(token) > 3) & (token[-3:] == '...'):\n",
    "            labels.append('...')\n",
    "        elif token[-1] in punctuation_signs:\n",
    "            labels.append(token[-1])\n",
    "        else:\n",
    "            labels.append('o')\n",
    "            \n",
    "    \n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d053dd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████| 5000/5000 [1:07:30<00:00,  1.23it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "true_labels = []\n",
    "\n",
    "for id_text in tqdm.tqdm(range(len(df_test.text.values))):\n",
    "    prediction= roberta_prediction(df_test.text.values[id_text])\n",
    "    needed_labels = ast.literal_eval(df_test.labels.values[id_text])\n",
    "    \n",
    "    # little bug in markup\n",
    "    if len(prediction) != len(needed_labels):        \n",
    "        not_empty_token_idxs = ~(np.array(ast.literal_eval(df_test.tokens.values[id_text])) == '')\n",
    "        needed_labels = np.array(needed_labels)[not_empty_token_idxs].tolist()\n",
    "        \n",
    "    if len(needed_labels) == len(prediction):\n",
    "        true_labels += needed_labels\n",
    "        preds += prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "607e2da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(211107, 211107)"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preds), len(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b7b9ce18",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = le.transform(preds)\n",
    "y_true = le.transform(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b2c437f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_metrics_no_proba(y_true, y_pred):\n",
    "    print('Доля пробелов:', (y_true == 7).mean())\n",
    "#     print('Accuracy:', top_k_accuracy_score(y_true, y_pred_proba, k=1))\n",
    "#     print('Top-2 Accuracy:', top_k_accuracy_score(y_true, y_pred_proba, k=2))\n",
    "#     rint('ROC-AUC (OVR):',roc_auc_score(y_true, y_pred_proba, multi_class='ovr'))\n",
    "#     print('AUC-PR:',average_precision_score(y_true, y_pred_proba, average='weighted'))\n",
    "    \n",
    "    metrics = []\n",
    "    metrics.append(list(dict(sorted(Counter(y_true).items())).values()))\n",
    "    metrics.append(f1_score(y_true, y_pred, average=None))\n",
    "    metrics.append(precision_score(y_true, y_pred, average=None, zero_division=0))\n",
    "    metrics.append(recall_score(y_true, y_pred, average=None, zero_division=0))\n",
    "#     metrics.append(roc_auc_score(y_true, y_pred_proba, multi_class='ovr', average=None))\n",
    "#     metrics.append(average_precision_score(y_true, y_pred_proba, average=None))\n",
    "    metrics_index = ['Count', 'F1-Score', 'Precision', 'Recall']\n",
    "#                      'ROC-AUC', 'AUC-PR']\n",
    "    df_metrics = pd.DataFrame(metrics, columns=le.classes_, index=metrics_index)\n",
    "    \n",
    "    return df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "45bccb44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля пробелов: 0.8498486549474911\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>,</th>\n",
       "      <th>.</th>\n",
       "      <th>...</th>\n",
       "      <th>:</th>\n",
       "      <th>;</th>\n",
       "      <th>?</th>\n",
       "      <th>o</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Count</th>\n",
       "      <td>48.0</td>\n",
       "      <td>15906.000000</td>\n",
       "      <td>14607.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>560.0</td>\n",
       "      <td>512.0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>179409.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1-Score</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.785240</td>\n",
       "      <td>0.812230</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.451613</td>\n",
       "      <td>0.982528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.742795</td>\n",
       "      <td>0.833501</td>\n",
       "      <td>0.244444</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.982887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.832830</td>\n",
       "      <td>0.792018</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.518519</td>\n",
       "      <td>0.982169</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              !             ,             .        ...      :      ;  \\\n",
       "Count      48.0  15906.000000  14607.000000  11.000000  560.0  512.0   \n",
       "F1-Score    0.0      0.785240      0.812230   0.392857    0.0    0.0   \n",
       "Precision   0.0      0.742795      0.833501   0.244444    0.0    0.0   \n",
       "Recall      0.0      0.832830      0.792018   1.000000    0.0    0.0   \n",
       "\n",
       "                   ?              o  \n",
       "Count      54.000000  179409.000000  \n",
       "F1-Score    0.451613       0.982528  \n",
       "Precision   0.400000       0.982887  \n",
       "Recall      0.518519       0.982169  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calc_metrics_no_proba(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81916f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
